#Intall python 3.5
#Add to list of interpreters in Pycharm https://www.jetbrains.com/help/pycharm-edu/adding-existing-virtual-environment.html
#Switch to it
#Install ethnicolr in pycharm settings
#For geopanda to work, need to install GDAL, Fiona, pyproj, six, shapely - see http://geopandas.org/install.html
#Never managed to get ESRI File GDB write drivers to work: https://gis.stackexchange.com/questions/193288/how-to-add-support-for-filegdb-esri-file-gdb-api-driver-in-fiona to get FileGDB writing support

import pandas as pd
import geopandas as gpd
import numpy as np
import ethnicolr
import os
import re

rootdir = 'C:\Mathis\ICSL\\flood_vulnerability'
resdir = os.path.join(rootdir,'results')
os.chdir(resdir)
gdb = 'flood_risk.gdb'

residindiv = pd.read_csv('parcel_taxrollname_residindiv.csv',
                         usecols=['PolyID','TaxRollID','party1_last1', 'party1_first1'],
                         dtype = {'PolyID': np.object, 'TaxRollID': np.object})
residindiv_full = residindiv[residindiv['party1_first1'].notnull() & residindiv['party1_last1'].notnull()]

parcelblock = pd.read_csv('parcels_blocksfill_subfield.csv', low_memory=False,
                          dtype = {'BLOCKID10': np.object, 'GEOID10_bg': np.object, 'GEOID10_t': np.object})
blockgroup = gpd.read_file(gdb, layer='blockgroup2010_proj')
tract = gpd.read_file(gdb, layer='tracts_WAproj')

#-----------------------------  PREDICT RACE/ETHINICITY OF INDIVIDUAL LAND OWNERS BASED ON THEIR NAME ------------------
#CENSUS 2010 LAST NAME DATABASE to predict race and ethnicity of individual land owners
# rdf_ln2010 = ethnicolr.census_ln(residindiv, 'party1_last1', 2010)
# rdf_ln2010.replace('(S)', 0, inplace=True)
# rdf_ln2010.to_csv(os.path.join(resdir,'parcel_taxrollname_residindiv_census_ln.csv'))
rdf_ln2010 = pd.read_csv(os.path.join(resdir, 'parcel_taxrollname_residindiv_census_ln.csv'),
                      dtype={'PolyID': np.object, 'TaxRollID': np.object, 'pctwhite': np.float64, 'pctblack': np.float64,
                             'pctapi': np.float64, 'pctaian': np.float64, 'pct2race':np.float64, 'pcthispanic':np.float64
                             })

#CENSUS 2010 LAST NAME model to predict the race and ethnicity of individual land owners
# rdfmod_ln2010 = ethnicolr.pred_census_ln(residindiv, 'party1_last1', 2010)
# rdfmod_ln2010.replace('(S)', 0, inplace=True)
# rdfmod_ln2010.to_csv(os.path.join(resdir,'parcel_taxrollname_residindiv_pred_census_ln.csv'))
rdfmod_ln2010 = pd.read_csv(os.path.join(resdir, 'parcel_taxrollname_residindiv_pred_census_ln.csv'),
                      dtype={'PolyID': np.object, 'TaxRollID': np.object})

#WIKIPEDIA LAST NAME model to predict the race and ethnicity of individual land owners
# wikilndf2010 = ethnicolr.pred_wiki_ln(residindiv, 'party1_last1')
# wikilndf2010.replace('(S)', 0, inplace=True)
# wikilndf2010.to_csv(os.path.join(resdir,'parcel_taxrollname_residindiv_pred_wiki_ln.csv'))
wikilndf2010 = pd.read_csv(os.path.join(resdir, 'parcel_taxrollname_residindiv_pred_wiki_ln.csv'),
                         dtype = {'PolyID':np.object, 'TaxRollID': np.object})

#WIKIPEDIA FULL NAME model to predict the race and ethnicity of individual land owners
# wikidf2010 = ethnicolr.pred_wiki_name(residindiv_full, 'party1_last1', 'party1_first1')
# wikidf2010.replace('(S)', 0, inplace=True)
# wikidf2010.to_csv(os.path.join(resdir,'parcel_taxrollname_residindiv_pred_wiki_name.csv'))
wikidf2010 = pd.read_csv(os.path.join(resdir, 'parcel_taxrollname_residindiv_pred_wiki_name.csv'),
                         dtype = {'PolyID':np.object, 'TaxRollID': np.object})

#FLORIDA REGISTRATION LAST NAME model to predict the race and ethnicity of individual land owners
# flreglndf2010 = ethnicolr.pred_fl_reg_ln(residindiv, 'party1_last1') #Doesn't work?
# flreglndf2010.replace('(S)', 0, inplace=True)
# flreglndf2010.to_csv(os.path.join(resdir,'parcel_taxrollname_residindiv_pred_flreg_name.csv'))
# flreglndf2010 = pd.read_csv(os.path.join(resdir, 'parcel_taxrollname_residindiv_pred_flreg_name.csv'),
#                          dtype = {'PolyID':np.object, 'TaxRollID': np.object})

#FLORIDA REGISTRATION FULL NAME model to predict the race and ethnicity of individual land owners
# flregdf2010 = ethnicolr.pred_fl_reg_name(residindiv_full, 'party1_last1', 'party1_first1')
# flregdf2010.replace('(S)', 0, inplace=True)
# flregdf2010.to_csv(os.path.join(resdir,'parcel_taxrollname_residindiv_pred_flreg_name.csv'))
flregdf2010 = pd.read_csv(os.path.join(resdir, 'parcel_taxrollname_residindiv_pred_flreg_name.csv'),
                         dtype = {'PolyID':np.object, 'TaxRollID': np.object})

#Merge all predictions together
#Join parcel info wikidf and rd
merge1a = rdfmod_ln2010.merge(rdf_ln2010, how ='outer', on = 'TaxRollID',
                       suffixes = ('_rdfmod', '_rdf'), copy = False)
merge1b = merge1a.merge(wikidf2010, how ='outer', on = 'TaxRollID',
                       suffixes = ('', '_wiki'), copy = False)
merge1c = merge1b.merge(wikilndf2010, how ='outer', on = 'TaxRollID',
                       suffixes = ('', '_wikiln'), copy = False)
# merge1d = merge1c.merge(flreglndf2010, how ='outer', on = 'TaxRollID',
#                        suffixes = ('', '_flregln'), copy = False)
merge1 = merge1c.merge(flregdf2010, how ='outer', on = 'TaxRollID',
                       suffixes = ('', '_flreg'), copy = False)
merge1 = merge1.drop(columns=['race', 'Unnamed: 0_rdf', 'PolyID_rdf', 'party1_last1_rdf',
                              'Unnamed: 0', 'PolyID', 'party1_last1','party1_first1', 'race_wiki',
                              'Unnamed: 0_wikiln', 'PolyID_wikiln', 'party1_last1_wikiln', 'race_wikiln',
                              'Unnamed: 0_flreg', 'PolyID_flreg','party1_last1_flreg', 'party1_first1_flreg', 'race_flreg'])

#-----------------------------  AGGREGATE RACE/ETHINICITY AT PARCEL LEVEL ----------------------------------------------
#----- Average predictions by parcel, count number of records by parcel, then write out to CSV export
meancols = merge1.columns[4:]
statdic = {}
for c in meancols:
    statdic[c] = 'mean'
statdic['TaxRollID'] = 'count'
parcel_raceag = merge1.groupby('PolyID_rdfmod').agg(statdic)
parcel_raceag = parcel_raceag.rename(index=str, columns={"TaxRollID": "TaxRollIDCount"})
parcel_raceag.index.name = 'PolyID'
parcel_raceag.reset_index(inplace=True)

#Then merge with parcel population size census data
merge2 = parcel_raceag.merge(parcelblock, how ='outer', on = 'PolyID', suffixes = ('', '_parcel'), copy = False)
merge2.to_csv(os.path.join(resdir,'parcels_blocksfill_racepred.csv'))
merge2 = pd.read_csv(os.path.join(resdir,'parcels_blocksfill_racepred.csv'), low_memory=False,
                          dtype = {'PolyID': np.object, 'BLOCKID10': np.object,
                                   'GEOID10_bg': np.object, 'GEOID10_t': np.object})
merge2['modsum'] = merge2['white'] + merge2['api'] + merge2['hispanic'] + merge2['black']
merge2['modsum_census'] = merge2['pctwhite'] + merge2['pctapi'] + merge2['pcthispanic'] + merge2['pctblack'] + \
                          merge2['pctaian'] + merge2['pct2prace']
#Total ; 3,598,851; PARCELPOP > 0: 2,051,130; PARCELPOP > 0 AND TaxRollIDCount >= 1: 1,761,674

#-----------------------------  AGGREGATE RACE/ETHINICITY AT BLOCKGROUP LEVEL ----------------------------------------------
#----- Aggregate by BLOCKGROUP, summing population columns and performing a weight average by parcel population on race
merge2_sub = merge2[(merge2['PARCELPOP']>0)]
sumcols = ['TaxRollIDCount', 'BLCKMAJ', 'HOUSINGADJ', 'PARCELPOP','TAXROLLNUM']
statdic = {}
for c in sumcols:
    statdic[c] = 'sum'
statdic['PARCELPOP'] = [statdic['PARCELPOP']] + ['mean']
bg_ag1 = merge2_sub.groupby('GEOID10_bg').agg(statdic)
bg_ag1.columns = ['_'.join(col).strip() for col in bg_ag1.columns.values]

#Function to run weighted average on all numeric columns in a df
def weighed_average(grp): #From https://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns
    return (grp._get_numeric_data().multiply(grp['PARCELPOP'], axis=0).sum())/grp['PARCELPOP'].sum()

#Run average on all race columns aside from those generated by census database model (as many more NaN in that one)
merge2_sub2 = merge2_sub[round(merge2_sub['modsum'],2)==1] #Make sure to only run average on parcels that have race prediction data
sub2_meancols = [c for c in list(meancols) if c not in list(rdf_ln2010.columns[4:])]
bg_ag2 = merge2_sub2[['GEOID10_bg','PARCELPOP']+list(sub2_meancols)].groupby('GEOID10_bg').apply(weighed_average)
#Run average on all base census model race columns
merge2_sub3 = merge2_sub[round(merge2_sub['modsum_census'],0)==100] #Make sure to only run average on parcels that have race prediction data
bg_ag3 = merge2_sub3[['GEOID10_bg','PARCELPOP']+list(rdf_ln2010.columns[4:])].groupby('GEOID10_bg').apply(weighed_average)

bg_ag4 = bg_ag1.merge(bg_ag2, how='outer', on = 'GEOID10_bg') #Merge two summary stat df
bg_ag = bg_ag4.merge(bg_ag3, how='outer', on = 'GEOID10_bg')
bg_ag.reset_index(inplace=True)
bg_ag = bg_ag.drop(columns=['PARCELPOP_x', 'PARCELPOP_y'])

#Subset blockgroup columns to include only data on race before exporting as .shp can only have 216 fields
regx_bgrace = re.compile('B02|B03', re.IGNORECASE)
racecols_bg = []
for c in blockgroup.columns:
    if regx_bgrace.match(c):
        racecols_bg.append(c)
keepcols = ['GEOID10', 'Shape_Length', 'Shape_Area','geometry']
blockgroup_attri = blockgroup[keepcols+racecols_bg].merge(bg_ag, how='outer', left_on = 'GEOID10', right_on = 'GEOID10_bg')
blockgroup_attri.columns = [c.split(',')[-1] for c in blockgroup_attri.columns] #Keep only most precise group for race/ethnicity to remove commas and shorten column names
blockgroup_attri.to_file('blockgroup_racepred.shp')

#-----------------------------  AGGREGATE RACE/ETHINICITY AT CENSUS TRACT LEVEL ----------------------------------------------
t_ag1 = merge2_sub.groupby('GEOID10_t').agg(statdic)
t_ag1.columns = ['_'.join(col).strip() for col in t_ag1.columns.values]
#Run average on all race columns aside from those generated by census database model (as many more NaN in that one)
t_ag2 = merge2_sub2[['GEOID10_t','PARCELPOP']+list(sub2_meancols)].groupby('GEOID10_t').apply(weighed_average)
#Run average on all base census model race columns
t_ag3 = merge2_sub3[['GEOID10_t','PARCELPOP']+list(rdf_ln2010.columns[4:])].groupby('GEOID10_t').apply(weighed_average)

t_ag4 = t_ag1.merge(t_ag2, how='outer', on = 'GEOID10_t') #Merge two summary stat df
t_ag = t_ag4.merge(t_ag3, how='outer', on = 'GEOID10_t')
t_ag.reset_index(inplace=True)
t_ag = t_ag.drop(columns=['PARCELPOP_x', 'PARCELPOP_y'])

#Subset tract columns to include only data on race before exporting as .shp can only have 216 fields
regx_trace = re.compile('DP008|DP009|DP011', re.IGNORECASE)
racecols_t = []
for c in tract.columns:
    if regx_trace.match(c):
        racecols_t.append(c)
tract_attri = tract[keepcols+racecols_t].merge(t_ag, how='outer', left_on = 'GEOID10', right_on = 'GEOID10_t')
tract_attri.columns = [c.split(',')[-1] for c in tract_attri.columns] #Keep only most precise group for race/ethnicity to remove commas and shorten column names
tract_attri.to_file('tract_racepred.shp')

#To do in the future:
    #- Only include those names for which parcel TaxRoll property address matches their mailing address to only keep those that
        # actually live in their place rather than owners of rental units
#For calibration:
    #- For those parcels with no race data, simply put it at probability from block group level